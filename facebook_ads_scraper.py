import requests
import time
import random
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains
import json
import urllib.parse
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Optional
import pandas as pd
from flask import Flask, request, jsonify
from flask_cors import CORS

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FacebookAdsLibraryScraper:
    def __init__(self, headless=True, use_proxy=False):
        self.base_url = "https://www.facebook.com/ads/library/"
        self.session = requests.Session()
        self.driver = None
        self.headless = headless
        self.use_proxy = use_proxy
        
        # Headers para parecer mais humano
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        self.session.headers.update(self.headers)
    
    def setup_driver(self):
        """Configura o WebDriver do Selenium"""
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.chrome.service import Service
        import os
        
        chrome_options = Options()
        
        if self.headless:
            chrome_options.add_argument("--headless")
        
        # Op√ß√µes para evitar detec√ß√£o e melhorar estabilidade
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-plugins")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--lang=pt-BR")
        
        # Configura√ß√µes para melhor performance
        chrome_options.add_argument("--disable-logging")
        chrome_options.add_argument("--disable-gpu-logging")
        chrome_options.add_argument("--silent")
        
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # Configura√ß√µes de proxy se necess√°rio
        if self.use_proxy:
            # Adicione suas configura√ß√µes de proxy aqui
            pass
        
        try:
            # Instalar ChromeDriver com corre√ß√£o para Windows
            driver_path = ChromeDriverManager().install()
            logger.info(f"ChromeDriver baixado em: {driver_path}")
            
            # Corrigir o caminho do ChromeDriver no Windows
            if os.name == 'nt':  # Windows
                driver_dir = os.path.dirname(driver_path)
                # Procurar pelo execut√°vel real
                for file in os.listdir(driver_dir):
                    if file.endswith('.exe') and 'chromedriver' in file.lower():
                        driver_path = os.path.join(driver_dir, file)
                        break
                else:
                    # Se n√£o encontrar, tentar na subpasta chromedriver-win32
                    win32_dir = os.path.join(driver_dir, 'chromedriver-win32')
                    if os.path.exists(win32_dir):
                        for file in os.listdir(win32_dir):
                            if file.endswith('.exe') and 'chromedriver' in file.lower():
                                driver_path = os.path.join(win32_dir, file)
                                break
            
            logger.info(f"ChromeDriver execut√°vel: {driver_path}")
            
            # Verificar se o arquivo existe
            if not os.path.exists(driver_path):
                raise FileNotFoundError(f"ChromeDriver n√£o encontrado em: {driver_path}")
            
            service = Service(driver_path)
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # Scripts para evitar detec√ß√£o
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.execute_script("Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]})")
            self.driver.execute_script("Object.defineProperty(navigator, 'languages', {get: () => ['pt-BR', 'pt', 'en']})")
            
            logger.info("ChromeDriver configurado com sucesso")
            return self.driver
            
        except Exception as e:
            logger.error(f"Erro ao configurar ChromeDriver: {e}")
            raise
    
    def build_search_url(self, query: str, country: str = "BR", 
                        active_status: str = "active", 
                        ad_type: str = "all",
                        media_type: str = "all",
                        search_type: str = "keyword_exact_phrase") -> str:
        """Constr√≥i a URL de busca baseada nos par√¢metros"""
        params = {
            'active_status': active_status,
            'ad_type': ad_type,
            'country': country,
            'is_targeted_country': 'false',
            'media_type': media_type,
            'q': f'"{query}"',
            'search_type': search_type,
            'source': 'fb-logo'
        }
        
        return f"{self.base_url}?{urllib.parse.urlencode(params)}"
    
    def human_delay(self, min_seconds=1, max_seconds=3):
        """Adiciona delay aleat√≥rio para simular comportamento humano"""
        delay = random.uniform(min_seconds, max_seconds)
        time.sleep(delay)
    
    def scroll_page(self, driver, scroll_pause_time=2):
        """Faz scroll na p√°gina para carregar mais conte√∫do"""
        last_height = driver.execute_script("return document.body.scrollHeight")
        
        while True:
            # Scroll para baixo
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # Aguarda carregar
            time.sleep(scroll_pause_time)
            
            # Calcula nova altura
            new_height = driver.execute_script("return document.body.scrollHeight")
            
            if new_height == last_height:
                break
            
            last_height = new_height
    
    def extract_ad_data(self, ad_element) -> Dict:
        """Extrai dados de um an√∫ncio espec√≠fico"""
        try:
            ad_data = {
                'advertiser_name': '',
                'ad_text': '',
                'ad_type': '',
                'start_date': '',
                'end_date': '',
                'impressions': '',
                'spend': '',
                'demographics': {},
                'locations': [],
                'image_urls': [],
                'video_urls': [],
                'link_url': '',
                'ad_id': '',
                'platforms': [],
                'scraped_at': datetime.now().isoformat()
            }
            
            # Pega todo o texto do elemento
            element_text = ''
            try:
                element_text = ad_element.text.strip()
            except:
                pass
            
            # Extrai ID da biblioteca de an√∫ncios
            try:
                if 'Identifica√ß√£o da biblioteca:' in element_text:
                    lines = element_text.split('\n')
                    for line in lines:
                        if 'Identifica√ß√£o da biblioteca:' in line:
                            ad_data['ad_id'] = line.replace('Identifica√ß√£o da biblioteca:', '').strip()
                            break
            except:
                pass
            
            # Extrai nome do anunciante - estrat√©gias m√∫ltiplas
            advertiser_name = ''
            
            # Estrat√©gia 1: Procura por texto antes de "Patrocinado"
            try:
                lines = element_text.split('\n')
                for i, line in enumerate(lines):
                    if 'Patrocinado' in line and i > 0:
                        potential_name = lines[i-1].strip()
                        if potential_name and len(potential_name) > 2 and len(potential_name) < 100:
                            advertiser_name = potential_name
                            break
            except:
                pass
            
            # Estrat√©gia 2: Procura por links do Facebook
            if not advertiser_name:
                try:
                    links = ad_element.find_elements(By.TAG_NAME, "a")
                    for link in links:
                        href = link.get_attribute('href') or ''
                        text = link.text.strip()
                        if 'facebook.com' in href and text and len(text) > 2:
                            advertiser_name = text
                            break
                except:
                    pass
            
            # Estrat√©gia 3: Procura na primeira linha v√°lida
            if not advertiser_name:
                try:
                    lines = element_text.split('\n')
                    for line in lines[:10]:  # Verifica as primeiras 10 linhas
                        line = line.strip()
                        if (len(line) > 2 and len(line) < 100 and 
                            not any(word in line.lower() for word in [
                                'biblioteca', 'an√∫ncios', 'filtros', 'resultado', 
                                'ativo', 'lan√ßados', 'veicula√ß√£o', 'plataformas'
                            ])):
                            advertiser_name = line
                            break
                except:
                    pass
            
            ad_data['advertiser_name'] = advertiser_name
            
            # Extrai texto do an√∫ncio
            ad_text = ''
            try:
                # Procura por texto ap√≥s "Patrocinado" at√© encontrar links ou metadata
                lines = element_text.split('\n')
                capturing = False
                captured_lines = []
                
                for line in lines:
                    line = line.strip()
                    
                    if 'Patrocinado' in line:
                        capturing = True
                        continue
                    
                    if capturing:
                        # Para de capturar se encontrar metadata ou links
                        if any(stop_word in line.lower() for stop_word in [
                            'ifood.com', 'facebook.com', 'identifica√ß√£o da biblioteca',
                            'veicula√ß√£o iniciada', 'plataformas', 'ver detalhes'
                        ]):
                            break
                        
                        # Adiciona linha se for texto relevante
                        if line and len(line) > 5 and not line.startswith('#'):
                            captured_lines.append(line)
                            
                        # Limita a quantidade de texto
                        if len(captured_lines) >= 5:
                            break
                
                ad_text = ' '.join(captured_lines)
                
                # Se n√£o conseguiu capturar assim, tenta outros m√©todos
                if not ad_text:
                    # Procura por par√°grafos com texto significativo
                    text_elements = ad_element.find_elements(By.XPATH, ".//p | .//div[string-length(text()) > 30]")
                    texts = []
                    for elem in text_elements[:3]:
                        text = elem.text.strip()
                        if (len(text) > 30 and len(text) < 500 and 
                            'Identifica√ß√£o da biblioteca' not in text and
                            'Veicula√ß√£o iniciada' not in text):
                            texts.append(text)
                    ad_text = ' '.join(texts)
                    
            except:
                pass
                
            ad_data['ad_text'] = ad_text[:500]  # Limita a 500 caracteres
            
            # Extrai data de in√≠cio
            try:
                if 'Veicula√ß√£o iniciada em' in element_text:
                    lines = element_text.split('\n')
                    for line in lines:
                        if 'Veicula√ß√£o iniciada em' in line:
                            ad_data['start_date'] = line.strip()
                            break
            except:
                pass
            
            # Extrai URLs de imagens
            try:
                img_elements = ad_element.find_elements(By.TAG_NAME, "img")
                image_urls = []
                for img in img_elements:
                    src = img.get_attribute('src')
                    if src and ('scontent' in src or 'fbcdn' in src):
                        image_urls.append(src)
                ad_data['image_urls'] = image_urls[:3]  # Limita a 3 imagens
            except:
                pass
            
            # Extrai link de destino
            try:
                links = ad_element.find_elements(By.TAG_NAME, "a")
                for link in links:
                    href = link.get_attribute('href') or ''
                    if any(domain in href for domain in ['ifood.com', 'instagram.com', 'whatsapp']):
                        ad_data['link_url'] = href
                        break
            except:
                pass
            
            # S√≥ retorna se encontrou dados √∫teis
            if ad_data['advertiser_name'] or (ad_data['ad_text'] and len(ad_data['ad_text']) > 30):
                return ad_data
            else:
                return {}
            
        except Exception as e:
            logger.error(f"Erro ao extrair dados do an√∫ncio: {str(e)}")
            return {}
    
    def search_ads_by_location_and_type(self, location: str, business_type: str, 
                                      max_results: int = 50) -> List[Dict]:
        """Busca an√∫ncios por localiza√ß√£o e tipo de neg√≥cio"""
        try:
            # Monta query de busca
            query = f"{business_type} {location}"
            
            # Configura driver
            if not self.driver:
                self.setup_driver()
            
            # Constr√≥i URL
            search_url = self.build_search_url(query)
            logger.info(f"Buscando an√∫ncios para: {query}")
            logger.info(f"URL: {search_url}")
            
            # Acessa a p√°gina
            self.driver.get(search_url)
            self.human_delay(3, 5)
            
            # Aguarda carregar
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            except:
                logger.warning("Timeout aguardando carregar p√°gina")
            
            # Scroll para carregar mais an√∫ncios
            self.scroll_page(self.driver)
            
            # Extrai an√∫ncios
            ads_data = []
            
            # Aguarda a p√°gina carregar completamente
            self.human_delay(5, 8)
            
            # Debug: salva screenshot para verificar o que est√° sendo carregado
            try:
                self.driver.save_screenshot("debug_page.png")
                logger.info("Screenshot salvo como debug_page.png")
            except:
                pass
            
            # Debug: verifica se chegou na p√°gina correta
            current_url = self.driver.current_url
            page_title = self.driver.title
            logger.info(f"URL atual: {current_url}")
            logger.info(f"T√≠tulo da p√°gina: {page_title}")
            
            # Verifica se h√° conte√∫do na p√°gina
            page_source = self.driver.page_source
            if "ads/library" not in current_url.lower():
                logger.warning("N√£o est√° na p√°gina da biblioteca de an√∫ncios")
                return []
            
            # Seletores mais robustos e espec√≠ficos para an√∫ncios individuais
            ad_selectors = [
                # Seletores mais espec√≠ficos para an√∫ncios individuais
                "div[data-testid='ad-card']",
                "div[role='article']",
                "div[data-ad-preview='message']",
                "div[data-testid='political-ad']",
                # Seletores baseados na estrutura da biblioteca de an√∫ncios
                "div[style*='border'] > div > div",
                "div[class*='result']",
                # Fallback para containers que contenham informa√ß√µes de an√∫ncios
                "div:has(a[href*='facebook.com']):has(img)",
            ]
            
            ads_found = []
            used_selector = None
            
            for selector in ad_selectors:
                try:
                    if ":has(" in selector:
                        # Para seletores CSS avan√ßados, usa JavaScript
                        elements = self.driver.execute_script("""
                            // Procura por elementos que parecem ser an√∫ncios individuais
                            const candidates = [];
                            const allDivs = document.querySelectorAll('div');
                            
                            allDivs.forEach(div => {
                                const text = div.textContent || '';
                                const hasLink = div.querySelector('a[href*="facebook.com"]') || div.querySelector('a[href*="ifood.com"]');
                                const hasImage = div.querySelector('img');
                                const hasPatrocinado = text.includes('Patrocinado') || text.includes('Sponsored');
                                const hasAdInfo = text.includes('Identifica√ß√£o da biblioteca') || text.includes('Veicula√ß√£o iniciada');
                                
                                // Verifica se √© um container de an√∫ncio v√°lido
                                if (hasPatrocinado && (hasLink || hasImage || hasAdInfo)) {
                                    // Verifica se n√£o √© um container muito grande (evita duplicatas)
                                    if (text.length < 2000) {
                                        candidates.push(div);
                                    }
                                }
                            });
                            
                            // Remove duplicatas baseado no conte√∫do
                            const unique = [];
                            const seen = new Set();
                            
                            candidates.forEach(candidate => {
                                const key = candidate.textContent.substring(0, 100);
                                if (!seen.has(key)) {
                                    seen.add(key);
                                    unique.push(candidate);
                                }
                            });
                            
                            return unique;
                        """)
                        if elements:
                            ads_found = elements
                            used_selector = selector
                            break
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            # Filtra elementos duplicados
                            unique_elements = []
                            seen_texts = set()
                            
                            for elem in elements:
                                try:
                                    text = elem.text[:100]  # Primeiros 100 caracteres como chave
                                    if text not in seen_texts and len(text) > 20:
                                        seen_texts.add(text)
                                        unique_elements.append(elem)
                                except:
                                    continue
                            
                            if unique_elements:
                                ads_found = unique_elements
                                used_selector = selector
                                logger.info(f"Encontrados {len(ads_found)} elementos √∫nicos com seletor: {selector}")
                                break
                except Exception as e:
                    logger.debug(f"Erro com seletor {selector}: {e}")
                    continue
            
            # Se n√£o encontrou com seletores espec√≠ficos, tenta busca mais focada
            if not ads_found:
                logger.warning("Tentando busca mais focada por an√∫ncios...")
                try:
                    # Busca espec√≠fica por elementos que contenham "Patrocinado"
                    elements = self.driver.execute_script("""
                        const ads = [];
                        const allElements = document.querySelectorAll('*');
                        
                        allElements.forEach(elem => {
                            const text = elem.textContent || '';
                            if (text.includes('Patrocinado') || text.includes('Sponsored')) {
                                // Procura o container pai que contenha o an√∫ncio completo
                                let container = elem;
                                for (let i = 0; i < 5; i++) {
                                    container = container.parentElement;
                                    if (!container) break;
                                    
                                    const containerText = container.textContent || '';
                                    if (containerText.includes('Identifica√ß√£o da biblioteca') || 
                                        containerText.includes('Veicula√ß√£o iniciada') ||
                                        containerText.length > 200) {
                                        ads.push(container);
                                        break;
                                    }
                                }
                            }
                        });
                        
                        // Remove duplicatas
                        const unique = [];
                        const seen = new Set();
                        
                        ads.forEach(ad => {
                            const key = ad.textContent.substring(0, 100);
                            if (!seen.has(key)) {
                                seen.add(key);
                                unique.push(ad);
                            }
                        });
                        
                        return unique.slice(0, 10); // M√°ximo 10 an√∫ncios √∫nicos
                    """)
                    
                    if elements:
                        ads_found = elements
                        used_selector = "busca_por_patrocinado"
                        
                except Exception as e:
                    logger.error(f"Erro na busca focada: {e}")
            
            if not ads_found:
                logger.warning("Nenhum an√∫ncio encontrado com nenhum seletor")
                return []
            
            logger.info(f"Usando seletor: {used_selector}, encontrados {len(ads_found)} elementos √∫nicos")
            
            # Extrai dados de cada an√∫ncio com filtragem de duplicatas
            ads_data = []
            seen_ads = set()  # Para evitar duplicatas
            
            for i, ad_element in enumerate(ads_found[:max_results]):
                try:
                    ad_data = self.extract_ad_data(ad_element)
                    
                    if ad_data and (ad_data.get('advertiser_name') or ad_data.get('ad_text')):
                        # Cria uma chave √∫nica para identificar duplicatas
                        ad_key = f"{ad_data.get('advertiser_name', '')[:50]}_{ad_data.get('ad_text', '')[:100]}"
                        ad_key = ad_key.lower().replace(' ', '').replace('\n', '')
                        
                        if ad_key not in seen_ads:
                            seen_ads.add(ad_key)
                            ads_data.append(ad_data)
                            
                            # Log melhorado
                            advertiser = ad_data.get('advertiser_name', 'N/A')
                            text_preview = ad_data.get('ad_text', '')[:50]
                            ad_id = ad_data.get('ad_id', 'N/A')
                            logger.info(f"An√∫ncio {len(ads_data)} extra√≠do: {advertiser} | ID: {ad_id} | Texto: {text_preview}...")
                        else:
                            logger.debug(f"An√∫ncio {i+1} ignorado (duplicata)")
                    else:
                        logger.debug(f"An√∫ncio {i+1} sem dados v√°lidos")
                    
                    # Delay entre extra√ß√µes
                    self.human_delay(0.3, 1.0)
                    
                except Exception as e:
                    logger.error(f"Erro ao extrair an√∫ncio {i+1}: {str(e)}")
                    continue
            
            # Se n√£o encontrou nenhum an√∫ncio v√°lido, retorna info de debug
            if not ads_data:
                logger.warning("Nenhum an√∫ncio v√°lido encontrado")
                try:
                    page_text = self.driver.find_element(By.TAG_NAME, "body").text
                    
                    # Verifica se h√° indica√ß√£o de que n√£o h√° an√∫ncios
                    if any(phrase in page_text.lower() for phrase in [
                        'nenhum resultado', 'no results', '0 resultado', 'sem an√∫ncios'
                    ]):
                        logger.info("P√°gina indica que n√£o h√° an√∫ncios para os crit√©rios especificados")
                        return []
                    
                    # Cria um an√∫ncio de debug apenas se necess√°rio
                    debug_ad = {
                        'advertiser_name': 'Debug - An√°lise da p√°gina',
                        'ad_text': 'P√°gina carregada mas nenhum an√∫ncio espec√≠fico foi extra√≠do',
                        'debug_info': f"URL: {self.driver.current_url}",
                        'page_sample': page_text[:300] + "...",
                        'scraped_at': datetime.now().isoformat()
                    }
                    return [debug_ad]
                    
                except Exception as e:
                    logger.error(f"Erro no m√©todo de debug: {e}")
                    return []
            
            logger.info(f"Total de an√∫ncios √∫nicos extra√≠dos: {len(ads_data)}")
            return ads_data
            
        except Exception as e:
            logger.error(f"Erro na busca de an√∫ncios: {str(e)}")
            return []
    
    def analyze_competition(self, location: str, business_type: str) -> Dict:
        """Analisa a concorr√™ncia em uma localiza√ß√£o espec√≠fica"""
        ads_data = self.search_ads_by_location_and_type(location, business_type)
        
        if not ads_data:
            return {
                'total_ads': 0,
                'active_advertisers': 0,
                'competition_level': 'baixa',
                'top_advertisers': [],
                'ad_types': {},
                'average_spend': 0,
                'analysis_date': datetime.now().isoformat()
            }
        
        # An√°lise dos dados
        advertisers = {}
        ad_types = {}
        
        for ad in ads_data:
            advertiser = ad.get('advertiser_name', 'Unknown')
            if advertiser in advertisers:
                advertisers[advertiser] += 1
            else:
                advertisers[advertiser] = 1
            
            ad_type = ad.get('ad_type', 'unknown')
            if ad_type in ad_types:
                ad_types[ad_type] += 1
            else:
                ad_types[ad_type] = 1
        
        # Determina n√≠vel de concorr√™ncia
        total_ads = len(ads_data)
        active_advertisers = len(advertisers)
        
        if total_ads >= 50:
            competition_level = 'alta'
        elif total_ads >= 20:
            competition_level = 'm√©dia'
        else:
            competition_level = 'baixa'
        
        # Top anunciantes
        top_advertisers = sorted(advertisers.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            'total_ads': total_ads,
            'active_advertisers': active_advertisers,
            'competition_level': competition_level,
            'top_advertisers': top_advertisers,
            'ad_types': ad_types,
            'analysis_date': datetime.now().isoformat(),
            'location': location,
            'business_type': business_type
        }
    
    def get_advertiser_info(self, advertiser_name: str) -> Dict:
        """Obt√©m informa√ß√µes espec√≠ficas de um anunciante"""
        try:
            query = advertiser_name
            ads_data = self.search_ads_by_location_and_type("", query, max_results=100)
            
            if not ads_data:
                return {
                    'advertiser_name': advertiser_name,
                    'total_ads': 0,
                    'has_active_ads': False,
                    'ad_types': [],
                    'locations': [],
                    'last_ad_date': None
                }
            
            # Processa dados do anunciante
            ad_types = set()
            locations = set()
            latest_date = None
            
            for ad in ads_data:
                if ad.get('advertiser_name', '').lower() == advertiser_name.lower():
                    ad_types.add(ad.get('ad_type', 'unknown'))
                    
                    # Processa localiza√ß√µes se dispon√≠vel
                    for location in ad.get('locations', []):
                        locations.add(location)
                    
                    # Processa datas
                    start_date = ad.get('start_date', '')
                    if start_date and ('Started' in start_date):
                        # Extrai data do texto
                        pass
            
            return {
                'advertiser_name': advertiser_name,
                'total_ads': len(ads_data),
                'has_active_ads': len(ads_data) > 0,
                'ad_types': list(ad_types),
                'locations': list(locations),
                'last_ad_date': latest_date,
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Erro ao obter informa√ß√µes do anunciante {advertiser_name}: {str(e)}")
            return {
                'advertiser_name': advertiser_name,
                'total_ads': 0,
                'has_active_ads': False,
                'error': str(e)
            }
    
    def close(self):
        """Fecha o driver e limpa recursos"""
        if self.driver:
            self.driver.quit()
            self.driver = None

    def check_establishment_by_address(self, maps_address: str) -> Dict:
        """Verifica se um estabelecimento tem an√∫ncios baseado no endere√ßo do Google Maps"""
        try:
            # Extrai informa√ß√µes do endere√ßo
            address_info = self.parse_maps_address(maps_address)
            
            if not address_info:
                return {
                    'establishment_found': False,
                    'has_ads': False,
                    'error': 'N√£o foi poss√≠vel extrair informa√ß√µes do endere√ßo fornecido',
                    'maps_address': maps_address
                }
            
            # Busca por an√∫ncios usando diferentes estrat√©gias
            search_strategies = []
            
            # Estrat√©gia 1: Nome do estabelecimento + cidade
            if address_info.get('name') and address_info.get('city'):
                search_strategies.append({
                    'query': f"{address_info['name']} {address_info['city']}",
                    'type': 'name_city'
                })
            
            # Estrat√©gia 2: Nome do estabelecimento + bairro
            if address_info.get('name') and address_info.get('neighborhood'):
                search_strategies.append({
                    'query': f"{address_info['name']} {address_info['neighborhood']}",
                    'type': 'name_neighborhood'
                })
            
            # Estrat√©gia 3: Apenas nome do estabelecimento
            if address_info.get('name'):
                search_strategies.append({
                    'query': address_info['name'],
                    'type': 'name_only'
                })
            
            # Estrat√©gia 4: Busca por categoria + localiza√ß√£o
            if address_info.get('category') and address_info.get('city'):
                search_strategies.append({
                    'query': f"{address_info['category']} {address_info['city']}",
                    'type': 'category_city'
                })
            
            all_ads = []
            matching_ads = []
            
            # Executa as estrat√©gias de busca
            for strategy in search_strategies:
                logger.info(f"Buscando com estrat√©gia {strategy['type']}: {strategy['query']}")
                
                try:
                    ads = self.search_ads_by_keywords(strategy['query'], max_results=20)
                    all_ads.extend(ads)
                    
                    # Verifica se algum an√∫ncio corresponde ao estabelecimento
                    for ad in ads:
                        if self.is_matching_establishment(ad, address_info):
                            matching_ads.append({
                                **ad,
                                'match_strategy': strategy['type'],
                                'match_confidence': self.calculate_match_confidence(ad, address_info)
                            })
                    
                    # Se encontrou correspond√™ncias, n√£o precisa continuar
                    if matching_ads:
                        break
                        
                except Exception as e:
                    logger.error(f"Erro na estrat√©gia {strategy['type']}: {e}")
                    continue
            
            # Ordena por confian√ßa da correspond√™ncia
            matching_ads.sort(key=lambda x: x.get('match_confidence', 0), reverse=True)
            
            return {
                'establishment_found': len(matching_ads) > 0,
                'has_ads': len(matching_ads) > 0,
                'total_matching_ads': len(matching_ads),
                'total_ads_searched': len(all_ads),
                'matching_ads': matching_ads[:5],  # Top 5 correspond√™ncias
                'establishment_info': address_info,
                'maps_address': maps_address,
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Erro ao verificar estabelecimento: {e}")
            return {
                'establishment_found': False,
                'has_ads': False,
                'error': str(e),
                'maps_address': maps_address,
                'analysis_date': datetime.now().isoformat()
            }
    
    def parse_maps_address(self, maps_address: str) -> Dict:
        """Extrai informa√ß√µes do endere√ßo do Google Maps"""
        try:
            # Parse b√°sico do endere√ßo - pode ser melhorado com regex mais complexas
            address_info = {
                'name': '',
                'street': '',
                'neighborhood': '',
                'city': '',
                'state': '',
                'category': '',
                'original_address': maps_address
            }
            
            # Estrat√©gias para extrair informa√ß√µes
            address_lower = maps_address.lower()
            
            # Extrai nome do estabelecimento (geralmente vem antes do primeiro h√≠fen ou v√≠rgula)
            if ' - ' in maps_address:
                potential_name = maps_address.split(' - ')[0].strip()
                if len(potential_name) > 2 and len(potential_name) < 100:
                    address_info['name'] = potential_name
            elif ',' in maps_address:
                potential_name = maps_address.split(',')[0].strip()
                if len(potential_name) > 2 and len(potential_name) < 100:
                    address_info['name'] = potential_name
            
            # Identifica cidades principais do Brasil
            brazilian_cities = [
                'rio de janeiro', 's√£o paulo', 'bras√≠lia', 'salvador', 'fortaleza',
                'belo horizonte', 'manaus', 'curitiba', 'recife', 'porto alegre',
                'goi√¢nia', 'bel√©m', 'guarulhos', 'campinas', 'nova igua√ßu',
                's√£o bernardo do campo', 'niter√≥i', 'florian√≥polis'
            ]
            
            for city in brazilian_cities:
                if city in address_lower:
                    address_info['city'] = city.title()
                    break
            
            # Identifica bairros comuns (pode ser expandido)
            common_neighborhoods = [
                'copacabana', 'ipanema', 'leblon', 'botafogo', 'tijuca',
                'barra da tijuca', 'centro', 'zona sul', 'zona norte',
                'vila ol√≠mpia', 'pinheiros', 'vila madalena', 'morumbi'
            ]
            
            for neighborhood in common_neighborhoods:
                if neighborhood in address_lower:
                    address_info['neighborhood'] = neighborhood.title()
                    break
            
            # Identifica categorias de estabelecimento
            categories = {
                'restaurante': ['restaurante', 'bar', 'lanchonete', 'pizzaria', 'hamburgueria'],
                'academia': ['academia', 'fitness', 'crossfit', 'pilates'],
                'sal√£o': ['sal√£o', 'barbershop', 'barbearia', 'cabeleireiro'],
                'loja': ['loja', 'store', 'boutique', 'magazine'],
                'hotel': ['hotel', 'pousada', 'hostel'],
                'cl√≠nica': ['cl√≠nica', 'consult√≥rio', 'm√©dico', 'dentista']
            }
            
            for category, keywords in categories.items():
                if any(keyword in address_lower for keyword in keywords):
                    address_info['category'] = category
                    break
            
            return address_info
            
        except Exception as e:
            logger.error(f"Erro ao fazer parse do endere√ßo: {e}")
            return None
    
    def search_ads_by_keywords(self, keywords: str, max_results: int = 20) -> List[Dict]:
        """Busca an√∫ncios por palavras-chave (m√©todo simplificado)"""
        try:
            # Configura driver se necess√°rio
            if not self.driver:
                self.setup_driver()
            
            # Constr√≥i URL de busca
            search_url = self.build_search_url(keywords)
            logger.info(f"Buscando an√∫ncios para palavras-chave: {keywords}")
            
            # Acessa a p√°gina
            self.driver.get(search_url)
            self.human_delay(2, 4)
            
            # Aguarda carregar
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            except:
                logger.warning("Timeout aguardando carregar p√°gina")
            
            # Busca an√∫ncios usando a mesma l√≥gica do m√©todo principal
            elements = self.driver.execute_script("""
                const ads = [];
                const allElements = document.querySelectorAll('*');
                
                allElements.forEach(elem => {
                    const text = elem.textContent || '';
                    if (text.includes('Patrocinado') || text.includes('Sponsored')) {
                        let container = elem;
                        for (let i = 0; i < 5; i++) {
                            container = container.parentElement;
                            if (!container) break;
                            
                            const containerText = container.textContent || '';
                            if (containerText.includes('Identifica√ß√£o da biblioteca') || 
                                containerText.length > 200) {
                                ads.push(container);
                                break;
                            }
                        }
                    }
                });
                
                // Remove duplicatas
                const unique = [];
                const seen = new Set();
                
                ads.forEach(ad => {
                    const key = ad.textContent.substring(0, 100);
                    if (!seen.has(key)) {
                        seen.add(key);
                        unique.push(ad);
                    }
                });
                
                return unique.slice(0, arguments[0]);
            """, max_results)
            
            # Extrai dados dos an√∫ncios encontrados
            ads_data = []
            for element in elements:
                try:
                    ad_data = self.extract_ad_data(element)
                    if ad_data and (ad_data.get('advertiser_name') or ad_data.get('ad_text')):
                        ads_data.append(ad_data)
                except:
                    continue
            
            return ads_data
            
        except Exception as e:
            logger.error(f"Erro na busca por palavras-chave: {e}")
            return []
    
    def is_matching_establishment(self, ad: Dict, establishment_info: Dict) -> bool:
        """Verifica se um an√∫ncio corresponde ao estabelecimento procurado"""
        try:
            ad_text = (ad.get('ad_text', '') + ' ' + ad.get('advertiser_name', '')).lower()
            
            # Verifica correspond√™ncia por nome
            if establishment_info.get('name'):
                name_lower = establishment_info['name'].lower()
                # Verifica correspond√™ncia exata ou parcial
                if name_lower in ad_text or any(word in ad_text for word in name_lower.split() if len(word) > 3):
                    return True
            
            # Verifica correspond√™ncia por localiza√ß√£o
            location_matches = 0
            if establishment_info.get('city'):
                if establishment_info['city'].lower() in ad_text:
                    location_matches += 1
            
            if establishment_info.get('neighborhood'):
                if establishment_info['neighborhood'].lower() in ad_text:
                    location_matches += 1
            
            # Se tem correspond√™ncia de localiza√ß√£o e categoria
            if location_matches > 0 and establishment_info.get('category'):
                if establishment_info['category'].lower() in ad_text:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Erro ao verificar correspond√™ncia: {e}")
            return False
    
    def calculate_match_confidence(self, ad: Dict, establishment_info: Dict) -> float:
        """Calcula a confian√ßa da correspond√™ncia entre an√∫ncio e estabelecimento"""
        try:
            confidence = 0.0
            ad_text = (ad.get('ad_text', '') + ' ' + ad.get('advertiser_name', '')).lower()
            
            # Correspond√™ncia de nome (peso alto)
            if establishment_info.get('name'):
                name_lower = establishment_info['name'].lower()
                if name_lower in ad_text:
                    confidence += 0.6
                elif any(word in ad_text for word in name_lower.split() if len(word) > 3):
                    confidence += 0.3
            
            # Correspond√™ncia de cidade (peso m√©dio)
            if establishment_info.get('city'):
                if establishment_info['city'].lower() in ad_text:
                    confidence += 0.2
            
            # Correspond√™ncia de bairro (peso m√©dio)
            if establishment_info.get('neighborhood'):
                if establishment_info['neighborhood'].lower() in ad_text:
                    confidence += 0.15
            
            # Correspond√™ncia de categoria (peso baixo)
            if establishment_info.get('category'):
                if establishment_info['category'].lower() in ad_text:
                    confidence += 0.05
            
            return min(confidence, 1.0)  # M√°ximo 1.0
            
        except Exception as e:
            logger.error(f"Erro ao calcular confian√ßa: {e}")
            return 0.0

# API Flask para integra√ß√£o
app = Flask(__name__)
CORS(app)

# Inst√¢ncia global do scraper
scraper = FacebookAdsLibraryScraper(headless=True)

@app.route('/')
def index():
    """P√°gina inicial com documenta√ß√£o da API"""
    return '''
<!DOCTYPE html>
<html>
<head>
    <title>Facebook Ads Scraper API</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }
        .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        h1 { color: #1877f2; text-align: center; }
        h2 { color: #333; border-bottom: 2px solid #1877f2; padding-bottom: 10px; }
        .endpoint { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #1877f2; }
        .method { background: #28a745; color: white; padding: 3px 8px; border-radius: 3px; font-size: 12px; }
        .method.post { background: #ffc107; color: #000; }
        .method.get { background: #17a2b8; }
        code { background: #e9ecef; padding: 2px 4px; border-radius: 3px; font-family: monospace; }
        .status { text-align: center; padding: 20px; background: #d4edda; border: 1px solid #c3e6cb; border-radius: 5px; color: #155724; }
        .example { background: #f8f9fa; padding: 10px; border-radius: 5px; margin: 10px 0; }
        pre { background: #f8f9fa; padding: 10px; border-radius: 5px; overflow-x: auto; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üîç Facebook Ads Scraper API</h1>
        
        <div class="status">
            <strong>‚úÖ API est√° funcionando!</strong><br>
            Servidor rodando em: http://127.0.0.1:5000
        </div>
        
        <h2>üìã Endpoints Dispon√≠veis</h2>
        
        <div class="endpoint">
            <h3><span class="method get">GET</span> /api/health</h3>
            <p>Verifica se o servi√ßo est√° funcionando</p>
            <div class="example">
                <strong>Exemplo:</strong><br>
                <code>GET http://127.0.0.1:5000/api/health</code>
            </div>
        </div>
        
        <div class="endpoint">
            <h3><span class="method post">POST</span> /api/analyze-competition</h3>
            <p>Analisa a concorr√™ncia para um nicho espec√≠fico</p>
            <div class="example">
                <strong>Payload:</strong>
                <pre>{"niche": "fitness", "location": "Brazil"}</pre>
            </div>
        </div>
        
        <div class="endpoint">
            <h3><span class="method post">POST</span> /api/check-advertiser</h3>
            <p>Verifica an√∫ncios de um anunciante espec√≠fico</p>
            <div class="example">
                <strong>Payload:</strong>
                <pre>{"advertiser_name": "Nike"}</pre>
            </div>
        </div>
        
        <div class="endpoint">
            <h3><span class="method post">POST</span> /api/check-establishment</h3>
            <p>Verifica se um estabelecimento tem an√∫ncios ativos (retorna detalhes completos)</p>
            <div class="example">
                <strong>Payload:</strong>
                <pre>{"maps_address": "Balada Mix - R. Barata Ribeiro, 111 - Copacabana, Rio de Janeiro - RJ"}</pre>
            </div>
        </div>
        
        <div class="endpoint">
            <h3><span class="method post">POST</span> /api/has-ads</h3>
            <p>Verifica√ß√£o r√°pida se um estabelecimento tem an√∫ncios (retorna apenas boolean)</p>
            <div class="example">
                <strong>Payload:</strong>
                <pre>{"maps_address": "Av. Paulista, 1578 - Bela Vista, S√£o Paulo - SP"}</pre>
                <strong>Resposta:</strong>
                <pre>{"has_ads": true}</pre>
            </div>
        </div>
        
        <div class="endpoint">
            <h3><span class="method post">POST</span> /api/search-ads</h3>
            <p>Busca an√∫ncios baseados em crit√©rios espec√≠ficos</p>
            <div class="example">
                <strong>Payload:</strong>
                <pre>{"keywords": "academia", "location": "Brazil", "business_type": "fitness"}</pre>
            </div>
        </div>
        
        <h2>üõ†Ô∏è Como Usar</h2>
        <p>Esta API permite fazer scraping da biblioteca de an√∫ncios do Facebook. Use as rotas acima para acessar diferentes funcionalidades.</p>
        
        <h3>Exemplo com cURL:</h3>
        <pre>curl -X POST http://127.0.0.1:5000/api/health</pre>
        
        <h3>Exemplo com Python:</h3>
        <pre>import requests

response = requests.post('http://127.0.0.1:5000/api/health')
print(response.json())</pre>
        
        <h2>üìä Status</h2>
        <p>Desenvolvido para an√°lise de concorr√™ncia e pesquisa de mercado atrav√©s da biblioteca de an√∫ncios do Facebook.</p>
    </div>
</body>
</html>
    '''

@app.route('/api/analyze-competition', methods=['POST'])
def analyze_competition():
    """Analisa a concorr√™ncia em uma localiza√ß√£o"""
    try:
        data = request.get_json()
        location = data.get('location', '')
        business_type = data.get('business_type', '')
        
        if not location or not business_type:
            return jsonify({
                'error': 'Localiza√ß√£o e tipo de neg√≥cio s√£o obrigat√≥rios'
            }), 400
        
        analysis = scraper.analyze_competition(location, business_type)
        return jsonify(analysis)
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/api/check-advertiser', methods=['POST'])
def check_advertiser():
    """Verifica se um anunciante espec√≠fico tem an√∫ncios ativos"""
    try:
        data = request.get_json()
        advertiser_name = data.get('advertiser_name', '')
        
        if not advertiser_name:
            return jsonify({
                'error': 'Nome do anunciante √© obrigat√≥rio'
            }), 400
        
        advertiser_info = scraper.get_advertiser_info(advertiser_name)
        return jsonify(advertiser_info)
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/api/search-ads', methods=['POST'])
def search_ads():
    """Busca an√∫ncios por localiza√ß√£o e tipo"""
    try:
        data = request.get_json()
        location = data.get('location', '')
        business_type = data.get('business_type', '')
        max_results = data.get('max_results', 50)
        
        if not location or not business_type:
            return jsonify({
                'error': 'Localiza√ß√£o e tipo de neg√≥cio s√£o obrigat√≥rios'
            }), 400
        
        ads = scraper.search_ads_by_location_and_type(location, business_type, max_results)
        
        return jsonify({
            'ads': ads,
            'total_found': len(ads),
            'location': location,
            'business_type': business_type
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/api/check-establishment', methods=['POST'])
def check_establishment():
    """Verifica se um estabelecimento tem an√∫ncios ativos baseado no endere√ßo do Google Maps"""
    try:
        data = request.get_json()
        maps_address = data.get('maps_address', '')
        
        if not maps_address:
            return jsonify({
                'error': 'Endere√ßo do Google Maps √© obrigat√≥rio'
            }), 400
        
        result = scraper.check_establishment_by_address(maps_address)
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/api/has-ads', methods=['POST'])
def has_ads():
    """Verifica se um estabelecimento tem an√∫ncios ativos - retorna apenas boolean"""
    try:
        data = request.get_json()
        maps_address = data.get('maps_address', '')
        
        if not maps_address:
            return jsonify({
                'has_ads': False,
                'error': 'Endere√ßo do Google Maps √© obrigat√≥rio'
            }), 400
        
        result = scraper.check_establishment_by_address(maps_address)
        
        return jsonify({
            'has_ads': result.get('has_ads', False)
        })
        
    except Exception as e:
        return jsonify({
            'has_ads': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health():
    """Verifica se o servi√ßo est√° funcionando"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    try:
        app.run(host='0.0.0.0', port=5000, debug=True)
    finally:
        scraper.close()
